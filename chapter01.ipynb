{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDe7DsPWmEBV"
      },
      "source": [
        "<h1>1ì¥ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì†Œê°œ</h1>\n",
        "<i>í¥ë¯¸ì§„ì§„í•œ ì–¸ì–´ AI ë¶„ì•¼ë¥¼ íƒí—˜í•©ë‹ˆë‹¤.</i>\n",
        "\n",
        "\n",
        "<a href=\"https://github.com/rickiepark/handson-llm\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/handson-llm/blob/main/chapter01.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ <[í•¸ì¦ˆì˜¨ LLM](https://tensorflow.blog/handson-llm/)> ì±… 1ì¥ì˜ ì½”ë“œë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "<a href=\"https://tensorflow.blog/handson-llm/\">\n",
        "<img src=\"https://tensorflow.blog/wp-content/uploads/2025/05/ed95b8eca688ec98a8_llm.jpg\" width=\"350\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buDa1--HJsJB"
      },
      "source": [
        "---\n",
        "\n",
        "ğŸ’¡ **NOTE**: ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Transformersë¡œ ì‚¬ì „í•™ìŠµ ì–¸ì–´ ëª¨ë¸(Phi-3)ì„ ë¶ˆëŸ¬ì™€ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ LLM í™œìš© ì‹¤ìŠµ"
      ],
      "metadata": {
        "id": "hSykZqiWY0Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 1. Hugging Face Transformersì˜ ë¡œê¹…(logging) ê¸°ëŠ¥ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "#    - ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ë•Œ\n",
        "#      í™”ë©´ì— 'ì§„í–‰ í‘œì‹œì¤„(progress bar)'ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n",
        "#    - í•˜ì§€ë§Œ GitHub, VS Code, ë˜ëŠ” Jupyter í™˜ê²½ì—ì„œëŠ”\n",
        "#      ì´ ì§„í–‰ í‘œì‹œì¤„ì´ ê¹¨ì§€ê±°ë‚˜ ë³´ì´ì§€ ì•Šì•„ ì—ëŸ¬ì²˜ëŸ¼ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "from transformers.utils import logging\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. ì§„í–‰ í‘œì‹œì¤„ ë„ê¸°\n",
        "#    - logging.disable_progress_bar()ë¥¼ ì‚¬ìš©í•˜ë©´\n",
        "#      ëª¨ë¸ ì‹¤í–‰ ì¤‘ì— ë‚˜íƒ€ë‚˜ëŠ” í”„ë¡œê·¸ë ˆìŠ¤ ë°”ë¥¼ ìˆ¨ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "#    - í™”ë©´ì´ ê¹”ë”í•´ì§€ê³  ì¶œë ¥ ì˜¤ë¥˜ê°€ ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "logging.disable_progress_bar()"
      ],
      "metadata": {
        "id": "cjSMRcEVwgV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXp09JFsFBXi"
      },
      "source": [
        "# Phi-3\n",
        "\n",
        "ì²« ë²ˆì§¸ ë‹¨ê³„ë¡œ ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•´ ëª¨ë¸ì„ GPUì— ë¡œë“œí•©ë‹ˆë‹¤. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ê°ê° ë¡œë“œí•©ë‹ˆë‹¤(í•­ìƒ ì´ë ‡ê²Œ í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSNalRXZyTTk",
        "outputId": "cc7f4088-3072-4c5b-e432-2d5fd138adb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. ì‚¬ìš©í•  ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "#    - AutoModelForCausalLM : \"ë¬¸ì¥ì„ ì´ì–´ì„œ ìƒì„±\"í•˜ëŠ” ëª¨ë¸ì„ ë¡œë“œí•  ë•Œ ì‚¬ìš©\n",
        "#    - AutoTokenizer        : ë¬¸ì¥ì„ ìˆ«ìë¡œ ë°”ê¾¸ê³ (í† í°í™”), ë‹¤ì‹œ ë¬¸ì¥ìœ¼ë¡œ ë°”ê¾¸ëŠ” ì—­í• \n",
        "# ---------------------------------------------------------\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "#    - \"microsoft/Phi-3-mini-4k-instruct\" ë¼ëŠ” ì´ë¦„ì˜ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë©”ëª¨ë¦¬ì— ì˜¬ë¦½ë‹ˆë‹¤.\n",
        "#    - device_map=\"cuda\" : ê·¸ë˜í”½ì¹´ë“œ(GPU)ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì„ ì‹¤í–‰í•˜ê² ë‹¤ëŠ” ëœ»\n",
        "#    - dtype=\"auto\"      : ëª¨ë¸ì´ ì•Œì•„ì„œ ì ì ˆí•œ ë°ì´í„° íƒ€ì…(ì •ë°€ë„)ì„ ì„ íƒí•˜ê²Œ í•¨\n",
        "# ---------------------------------------------------------\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",  # GPU ì‚¬ìš©\n",
        "    dtype=\"auto\",       # ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ìµœì  ë°ì´í„° íƒ€ì… ì„ íƒ\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "#    - ê°™ì€ ì´ë¦„ì˜ ëª¨ë¸ìš© í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "#    - í† í¬ë‚˜ì´ì €ëŠ” ì‚¬ëŒì´ ì½ëŠ” ë¬¸ì¥ì„ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” 'ìˆ«ì(í† í°)'ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.\n",
        "#    - ëª¨ë¸ì˜ ì¶œë ¥(ìˆ«ì)ì„ ë‹¤ì‹œ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë˜ëŒë¦´ ë•Œë„ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "# ---------------------------------------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdyYYS0E5fEU"
      },
      "source": [
        "ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ `pipeline` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í›¨ì”¬ ì‰½ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pipeline() â†’ ëª¨ë¸ ì‚¬ìš©ì„ ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ìë™ ì—°ê²° ì¥ì¹˜\n",
        "\n",
        "- \"text-generation\" â†’ â€œë¬¸ì¥ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”â€ ì‘ì—…ì„ ì„ íƒí•˜ëŠ” ê²ƒ\n",
        "\n",
        "- generator(\"ë¬¸ì¥\") â†’ ì´ì–´ì§€ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤Œ\n",
        "\n",
        "- do_sample=False â†’ ëœë¤ ì—†ì´ ì•ˆì •ì Â·ì¼ê´€ëœ ë‹µë³€\n",
        "\n",
        "- max_new_tokens â†’ ìƒì„±ë˜ëŠ” ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ ì„¤ì •"
      ],
      "metadata": {
        "id": "469GzR9NTQrj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiUi4Wu1FCyN",
        "outputId": "918314ef-10aa-41d5-f0a0-ff725a21916b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ë§Œë“¤ê¸°\n",
        "#    pipeline() í•¨ìˆ˜ëŠ” ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì—°ê²°í•´ì„œ\n",
        "#    ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” â€œí…ìŠ¤íŠ¸ ìƒì„±ê¸°â€ë¥¼ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
        "#\n",
        "#    ì˜ˆë¥¼ ë“¤ì–´,\n",
        "#    generator(\"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ”\")  â†’ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì„ ìë™ìœ¼ë¡œ ìƒì„±í•´ ì¤ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "generator = pipeline(\n",
        "    \"text-generation\",  # ì–´ë–¤ ì‘ì—…ì„ í• ì§€ ì„ íƒ â†’ ì—¬ê¸°ì„œëŠ” 'í…ìŠ¤íŠ¸ ìƒì„±'\n",
        "    model=model,        # ì•ì—ì„œ ë¶ˆëŸ¬ì˜¨ ì–¸ì–´ ëª¨ë¸ ì‚¬ìš©\n",
        "    tokenizer=tokenizer,# ë¬¸ì¥ â†” ìˆ«ì(í† í°) ë³€í™˜ì„ ë‹´ë‹¹í•˜ëŠ” í† í¬ë‚˜ì´ì €\n",
        "    return_full_text=False, # ì…ë ¥ ë¬¸ì¥ì„ ê²°ê³¼ì— ë‹¤ì‹œ í¬í•¨í•˜ì§€ ì•Šë„ë¡ ì„¤ì •\n",
        "    max_new_tokens=500, # ëª¨ë¸ì´ ìƒˆë¡œ ë§Œë“¤ì–´ë‚¼ ìµœëŒ€ ê¸€ì ìˆ˜(í† í° ìˆ˜)\n",
        "    do_sample=False     # ëœë¤ì´ ì•„ë‹Œ 'ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²°ê³¼'ë§Œ ì„ íƒ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD49kysT5mMY"
      },
      "source": [
        "ë§ˆì§€ë§‰ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ê³  ëª¨ë¸ì— ì£¼ì…í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- messages = ëª¨ë¸ì—ê²Œ ì¤„ ì§ˆë¬¸\n",
        "- generator(messages) = ëª¨ë¸ì´ ë‹µë³€ ìƒì„±\n",
        "- output[0][\"generated_text\"] = ë§Œë“¤ì–´ì§„ ìµœì¢… ë¬¸ì¥"
      ],
      "metadata": {
        "id": "HP1yGGMsTm9D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkR7LBmiyXmY",
        "outputId": "6c614f4e-d995-4f67-8c65-8084e2bc98e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Why did the chicken join the band? Because it had the drumsticks!\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------\n",
        "# 1. í”„ë¡¬í”„íŠ¸(ì‚¬ìš©ì ìš”ì²­) ë§Œë“¤ê¸°\n",
        "#    - ëª¨ë¸ì—ê²Œ \"ì–´ë–¤ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë‹¬ë¼\"ë¼ê³  ìš”ì²­í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
        "#    - messages ë¦¬ìŠ¤íŠ¸ ì•ˆì— roleê³¼ contentë¥¼ ë„£ëŠ” êµ¬ì¡°ëŠ”\n",
        "#      'ëŒ€í™”í˜• ëª¨ë¸(ChatGPT ìŠ¤íƒ€ì¼)'ê³¼ ë¹„ìŠ·í•œ í˜•ì‹ì…ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
        "    # role: \"user\" â†’ ì‚¬ëŒì´ í•œ ë§\n",
        "    # content: ì‹¤ì œ ìš”ì²­ ë‚´ìš© (ì¹˜í‚¨ì— ëŒ€í•œ ë†ë‹´ ë§Œë“¤ì–´ì¤˜)\n",
        "]\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. ìƒì„±ê¸°(generator)ë¥¼ ì´ìš©í•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ë‚´ê¸°\n",
        "#    - generator(messages)ë¥¼ í˜¸ì¶œí•˜ë©´\n",
        "#      ëª¨ë¸ì´ messages ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "output = generator(messages)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. ìƒì„±ëœ ë¬¸ì¥ ì¶œë ¥í•˜ê¸°\n",
        "#    - outputì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‚˜ì˜¤ë©°,\n",
        "#      ê·¸ ì¤‘ ì²« ë²ˆì§¸ ê²°ê³¼ì˜ \"generated_text\"ì— ìƒì„±ëœ ë¬¸ì¥ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "print(output[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 1. í”„ë¡¬í”„íŠ¸(ì‚¬ìš©ì ìš”ì²­) ë§Œë“¤ê¸°\n",
        "#    - ëª¨ë¸ì—ê²Œ \"ì–´ë–¤ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë‹¬ë¼\"ë¼ê³  ìš”ì²­í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
        "#    - messages ë¦¬ìŠ¤íŠ¸ ì•ˆì— roleê³¼ contentë¥¼ ë„£ëŠ” êµ¬ì¡°ëŠ”\n",
        "#      'ëŒ€í™”í˜• ëª¨ë¸(ChatGPT ìŠ¤íƒ€ì¼)'ê³¼ ë¹„ìŠ·í•œ í˜•ì‹ì…ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"ì¹˜í‚¨ì— ëŒ€í•œ ë†ë‹´ ë§Œë“¤ì–´ì¤˜\"}\n",
        "    # role: \"user\" â†’ ì‚¬ëŒì´ í•œ ë§\n",
        "    # content: ì‹¤ì œ ìš”ì²­ ë‚´ìš© (ì¹˜í‚¨ì— ëŒ€í•œ ë†ë‹´ ë§Œë“¤ì–´ì¤˜)\n",
        "]\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. ìƒì„±ê¸°(generator)ë¥¼ ì´ìš©í•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ë‚´ê¸°\n",
        "#    - generator(messages)ë¥¼ í˜¸ì¶œí•˜ë©´\n",
        "#      ëª¨ë¸ì´ messages ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "output = generator(messages)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. ìƒì„±ëœ ë¬¸ì¥ ì¶œë ¥í•˜ê¸°\n",
        "#    - outputì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‚˜ì˜¤ë©°,\n",
        "#      ê·¸ ì¤‘ ì²« ë²ˆì§¸ ê²°ê³¼ì˜ \"generated_text\"ì— ìƒì„±ëœ ë¬¸ì¥ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "Th_u6xWvZEmn",
        "outputId": "1eadcadd-4847-4c8b-914b-9f69510c9321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ì¹˜í‚¨ ë†ë‹´:\n",
            "\n",
            "\"ì¹˜í‚¨ ë¨¹ê¸° ì „ì— ë¨¹ì„ ë•Œ ì¹˜í‚¨ ë°°ì¶”ë¥¼ ë¨¹ì–´ì•¼ ì¹˜í‚¨ì´ ë” ë§›ìˆì–´ìš”. ê·¸ëŸ¼ ë¨¹ì„ ë•Œ ë°°ì¶”ë¥¼ ë¨¹ìœ¼ë©´ ì¹˜í‚¨ì´ ë” ë§›ìˆì–´ìš”.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 1. í”„ë¡¬í”„íŠ¸(ì‚¬ìš©ì ìš”ì²­) ë§Œë“¤ê¸°\n",
        "#    - ëª¨ë¸ì—ê²Œ \"ì–´ë–¤ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë‹¬ë¼\"ë¼ê³  ìš”ì²­í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
        "#    - messages ë¦¬ìŠ¤íŠ¸ ì•ˆì— roleê³¼ contentë¥¼ ë„£ëŠ” êµ¬ì¡°ëŠ”\n",
        "#      'ëŒ€í™”í˜• ëª¨ë¸(ChatGPT ìŠ¤íƒ€ì¼)'ê³¼ ë¹„ìŠ·í•œ í˜•ì‹ì…ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œ?\"}\n",
        "    # role: \"user\" â†’ ì‚¬ëŒì´ í•œ ë§\n",
        "    # content: ì‹¤ì œ ìš”ì²­ ë‚´ìš©\n",
        "]\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. ìƒì„±ê¸°(generator)ë¥¼ ì´ìš©í•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ë‚´ê¸°\n",
        "#    - generator(messages)ë¥¼ í˜¸ì¶œí•˜ë©´\n",
        "#      ëª¨ë¸ì´ messages ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "output = generator(messages)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. ìƒì„±ëœ ë¬¸ì¥ ì¶œë ¥í•˜ê¸°\n",
        "#    - outputì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‚˜ì˜¤ë©°,\n",
        "#      ê·¸ ì¤‘ ì²« ë²ˆì§¸ ê²°ê³¼ì˜ \"generated_text\"ì— ìƒì„±ëœ ë¬¸ì¥ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "# -----------------------------------------------------------\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "xFCBCBR4ZTTp",
        "outputId": "6ad0f5b6-835e-4c10-82ab-ce2f152cc74e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ì €ëŠ” 2023ë…„ 8ì›” 10ì¼ ì˜¤í›„ 3ì‹œì— ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤. í˜„ì¬ ì„œìš¸ ì§€ì—­ì˜ ë‚ ì”¨ëŠ” í‰ìƒìœ¼ë¡œ ì•½ 25â„ƒì˜ ê¸°ì˜¨ì´ ìˆê³ , í’ì†ì€ 10m/së¡œ ìˆìŠµë‹ˆë‹¤. í•˜ëŠ˜ì€ í‘¸ë¥¸ìƒ‰ì´ê³  ë¹„ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚ ì”¨ ì •ë³´ëŠ” ë‹¹ì‹ ì˜ ì§€ì—­ì— ë”°ë¼ ì¡°ê¸ˆì”© ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœì‹  ì§€ì—­ ë³„ ë‚ ì”¨ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}